{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":41875,"databundleVersionId":5521661,"sourceType":"competition"},{"sourceId":5607816,"sourceType":"datasetVersion","datasetId":3225525},{"sourceId":5792099,"sourceType":"datasetVersion","datasetId":3327296},{"sourceId":6180004,"sourceType":"datasetVersion","datasetId":3546496}],"dockerImageVersionId":30527,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nsub = pd.read_csv(\"/kaggle/input/cafa-5-protein-function-prediction/sample_submission.tsv\", sep= \"\\t\", header = None)\nsub.columns = [\"The Protein ID\", \"The Gene Ontology term (GO) ID\", \"Predicted link probability that GO appear in Protein\"]\nsub.head(5)","metadata":{"execution":{"iopub.status.busy":"2023-06-10T12:27:11.996045Z","iopub.execute_input":"2023-06-10T12:27:11.996589Z","iopub.status.idle":"2023-06-10T12:27:12.219293Z","shell.execute_reply.started":"2023-06-10T12:27:11.996555Z","shell.execute_reply":"2023-06-10T12:27:12.218403Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"MAIN_DIR = \"/kaggle/input/cafa-5-protein-function-prediction\"\n\n# UTILITARIES\nimport numpy as np\nfrom tqdm import tqdm\nimport time\nimport matplotlib.pyplot as plt\nplt.style.use('ggplot')\n\n# TORCH MODULES FOR METRICS COMPUTATION :\nimport torch\nfrom torch.utils.data import Dataset\nfrom torch import nn\nfrom torch.utils.data import random_split\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau\nfrom torchmetrics.classification import MultilabelF1Score\nfrom torchmetrics.classification import MultilabelAccuracy\n\nimport pytorch_lightning as pl\nfrom pytorch_lightning import Trainer\nfrom pytorch_lightning.loggers import WandbLogger\n\n# WANDB FOR LIGHTNING :\nimport wandb\n\n# FILES VISUALIZATION\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-06-10T12:28:25.773695Z","iopub.execute_input":"2023-06-10T12:28:25.774061Z","iopub.status.idle":"2023-06-10T12:28:37.88911Z","shell.execute_reply.started":"2023-06-10T12:28:25.774031Z","shell.execute_reply":"2023-06-10T12:28:37.8881Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class config:\n    train_sequences_path = MAIN_DIR  + \"/Train/train_sequences.fasta\"\n    train_labels_path = MAIN_DIR + \"/Train/train_terms.tsv\"\n    test_sequences_path = MAIN_DIR + \"/Test (Targets)/testsuperset.fasta\"\n    \n    num_labels = 500\n    n_epochs = 5\n    batch_size = 128\n    lr = 0.01\n    \n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"execution":{"iopub.status.busy":"2023-06-10T12:32:46.999405Z","iopub.execute_input":"2023-06-10T12:32:46.99998Z","iopub.status.idle":"2023-06-10T12:32:47.018051Z","shell.execute_reply.started":"2023-06-10T12:32:46.999936Z","shell.execute_reply":"2023-06-10T12:32:47.014509Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(config.device)","metadata":{"execution":{"iopub.status.busy":"2023-06-10T12:28:37.907778Z","iopub.execute_input":"2023-06-10T12:28:37.908444Z","iopub.status.idle":"2023-06-10T12:28:37.913751Z","shell.execute_reply.started":"2023-06-10T12:28:37.908412Z","shell.execute_reply":"2023-06-10T12:28:37.912807Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Directories for the different embedding vectors : \nembeds_map = {\n    \"T5\" : \"t5embeds\",\n    \"ProtBERT\" : \"protbert-embeddings-for-cafa5\",\n    \"EMS2\" : \"cafa-5-ems-2-embeddings-numpy\"\n}\n\n# Length of the different embedding vectors :\nembeds_dim = {\n    \"T5\" : 1024,\n    \"ProtBERT\" : 1024,\n    \"EMS2\" : 1280\n}","metadata":{"execution":{"iopub.status.busy":"2023-06-10T12:28:37.948982Z","iopub.execute_input":"2023-06-10T12:28:37.949523Z","iopub.status.idle":"2023-06-10T12:28:37.954513Z","shell.execute_reply.started":"2023-06-10T12:28:37.949493Z","shell.execute_reply":"2023-06-10T12:28:37.953508Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class ProteinSequenceDataset(Dataset):\n    \n    def __init__(self, datatype, embeddings_source):\n        super(ProteinSequenceDataset).__init__()\n        self.datatype = datatype\n        \n        if embeddings_source in [\"ProtBERT\", \"EMS2\"]:\n            embeds = np.load(\"/kaggle/input/\"+embeds_map[embeddings_source]+\"/\"+datatype+\"_embeddings.npy\")\n            ids = np.load(\"/kaggle/input/\"+embeds_map[embeddings_source]+\"/\"+datatype+\"_ids.npy\")\n        \n        if embeddings_source == \"T5\":\n            embeds = np.load(\"/kaggle/input/\"+embeds_map[embeddings_source]+\"/\"+datatype+\"_embeds.npy\")\n            ids = np.load(\"/kaggle/input/\"+embeds_map[embeddings_source]+\"/\"+datatype+\"_ids.npy\")\n            \n        embeds_list = []\n        for l in range(embeds.shape[0]):\n            embeds_list.append(embeds[l,:])\n        self.df = pd.DataFrame(data={\"EntryID\": ids, \"embed\" : embeds_list})\n        \n        if datatype==\"train\":\n            np_labels = np.load(\n                \"/kaggle/input/train-targets-top\"+str(config.num_labels)+ \\\n                \"/train_targets_top\"+str(config.num_labels)+\".npy\")\n            df_labels = pd.DataFrame(self.df['EntryID'])\n            df_labels['labels_vect']=[row for row in np_labels]\n            self.df = self.df.merge(df_labels, on=\"EntryID\")\n            \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, index):\n        embed = torch.tensor(self.df.iloc[index][\"embed\"] , dtype = torch.float32)\n        if self.datatype==\"train\":\n            targets = torch.tensor(self.df.iloc[index][\"labels_vect\"], dtype = torch.float32)\n            return embed, targets\n        if self.datatype==\"test\":\n            id = self.df.iloc[index][\"EntryID\"]\n            return embed, id\n        ","metadata":{"execution":{"iopub.status.busy":"2023-06-10T12:28:40.86426Z","iopub.execute_input":"2023-06-10T12:28:40.864637Z","iopub.status.idle":"2023-06-10T12:28:40.878496Z","shell.execute_reply.started":"2023-06-10T12:28:40.864607Z","shell.execute_reply":"2023-06-10T12:28:40.876685Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## MODEL ARCHITECTURE BUILDING AND TRAINING","metadata":{}},{"cell_type":"code","source":"class MultiLayerPerceptron(torch.nn.Module):\n\n    def __init__(self, input_dim, num_classes):\n        super(MultiLayerPerceptron, self).__init__()\n\n        self.linear1 = torch.nn.Linear(input_dim, 864)\n        self.activation1 = torch.nn.ReLU() \n        self.linear2 = torch.nn.Linear(864, 712)\n        self.activation2 = torch.nn.ReLU()\n        self.linear3 = torch.nn.Linear(712, num_classes)\n      \n\n    def forward(self, x):\n        x = self.linear1(x)\n        x = self.activation1(x)\n        x = self.linear2(x)\n        x = self.activation2(x)\n        x = self.linear3(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2023-06-10T12:30:31.424178Z","iopub.execute_input":"2023-06-10T12:30:31.424556Z","iopub.status.idle":"2023-06-10T12:30:31.432271Z","shell.execute_reply.started":"2023-06-10T12:30:31.424524Z","shell.execute_reply":"2023-06-10T12:30:31.431322Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class CNN1D(nn.Module):\n    def __init__(self, input_dim, num_classes):\n        super(CNN1D, self).__init__()\n        # (batch_size, channels, embed_size)\n        self.conv1 = nn.Conv1d(in_channels=1, out_channels=3, kernel_size=3, dilation=1, padding=1, stride=1)\n        # (batch_size, 3, embed_size)\n        self.pool1 = nn.MaxPool1d(kernel_size=2, stride=2)\n        # (batch_size, 3, embed_size/2 = 512)\n        self.conv2 = nn.Conv1d(in_channels=3, out_channels=8, kernel_size=3, dilation=1, padding=1, stride=1)\n        # (batch_size, 8, embed_size/2 = 512)\n        self.pool2 = nn.MaxPool1d(kernel_size=2, stride=2)\n        # (batch_size, 8, embed_size/4 = 256)\n        self.fc1 = nn.Linear(in_features=int(8 * input_dim/4), out_features=864)\n        self.fc2 = nn.Linear(in_features=864, out_features=num_classes)\n\n    def forward(self, x):\n        x = x.reshape(x.shape[0], 1, x.shape[1])\n        x = self.pool1(nn.functional.tanh(self.conv1(x)))\n        x = self.pool2(nn.functional.tanh(self.conv2(x)))\n        x = torch.flatten(x, 1)\n        x = nn.functional.tanh(self.fc1(x))\n        x = self.fc2(x)\n        return x\n","metadata":{"execution":{"iopub.status.busy":"2023-06-10T12:28:44.752653Z","iopub.execute_input":"2023-06-10T12:28:44.752992Z","iopub.status.idle":"2023-06-10T12:28:44.764379Z","shell.execute_reply.started":"2023-06-10T12:28:44.752966Z","shell.execute_reply":"2023-06-10T12:28:44.763364Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def train_model(embeddings_source, model_type=\"linear\", train_size=0.9):\n    \n    train_dataset = ProteinSequenceDataset(datatype=\"train\", embeddings_source = embeddings_source)\n    \n    train_set, val_set = random_split(train_dataset, lengths = [int(len(train_dataset)*train_size), len(train_dataset)-int(len(train_dataset)*train_size)])\n    train_dataloader = torch.utils.data.DataLoader(train_set, batch_size=config.batch_size, shuffle=True)\n    val_dataloader = torch.utils.data.DataLoader(val_set, batch_size=config.batch_size, shuffle=True)\n\n    if model_type == \"linear\":\n        model = MultiLayerPerceptron(input_dim=embeds_dim[embeddings_source], num_classes=config.num_labels).to(config.device)\n    if model_type == \"convolutional\":\n        model = CNN1D(input_dim=embeds_dim[embeddings_source], num_classes=config.num_labels).to(config.device)\n\n    optimizer = torch.optim.Adam(model.parameters(), lr = config.lr)\n    scheduler = ReduceLROnPlateau(optimizer, factor=0.1, patience=1)\n    CrossEntropy = torch.nn.CrossEntropyLoss()\n    f1_score = MultilabelF1Score(num_labels=config.num_labels).to(config.device)\n    n_epochs = config.n_epochs\n\n    print(\"BEGIN TRAINING...\")\n    train_loss_history=[]\n    val_loss_history=[]\n    \n    train_f1score_history=[]\n    val_f1score_history=[]\n    for epoch in range(n_epochs):\n        print(\"EPOCH \", epoch+1)\n        ## TRAIN PHASE :\n        losses = []\n        scores = []\n        for embed, targets in tqdm(train_dataloader):\n            embed, targets = embed.to(config.device), targets.to(config.device)\n            optimizer.zero_grad()\n            preds = model(embed)\n            loss= CrossEntropy(preds, targets)\n            score=f1_score(preds, targets)\n            losses.append(loss.item()) \n            scores.append(score.item())\n            loss.backward()\n            optimizer.step()\n        avg_loss = np.mean(losses)\n        avg_score = np.mean(scores)\n        print(\"Running Average TRAIN Loss : \", avg_loss)\n        print(\"Running Average TRAIN F1-Score : \", avg_score)\n        train_loss_history.append(avg_loss)\n        train_f1score_history.append(avg_score)\n        \n        ## VALIDATION PHASE : \n        losses = []\n        scores = []\n        for embed, targets in val_dataloader:\n            embed, targets = embed.to(config.device), targets.to(config.device)\n            preds = model(embed)\n            loss= CrossEntropy(preds, targets)\n            score=f1_score(preds, targets)\n            losses.append(loss.item())\n            scores.append(score.item())\n        avg_loss = np.mean(losses)\n        avg_score = np.mean(scores)\n        print(\"Running Average VAL Loss : \", avg_loss)\n        print(\"Running Average VAL F1-Score : \", avg_score)\n        val_loss_history.append(avg_loss)\n        val_f1score_history.append(avg_score)\n        \n        scheduler.step(avg_loss)\n        print(\"\\n\")\n        \n    print(\"TRAINING FINISHED\")\n    print(\"FINAL TRAINING SCORE : \", train_f1score_history[-1])\n    print(\"FINAL VALIDATION SCORE : \", val_f1score_history[-1])\n    \n    losses_history = {\"train\" : train_loss_history, \"val\" : val_loss_history}\n    scores_history = {\"train\" : train_f1score_history, \"val\" : val_f1score_history}\n    \n    return model, losses_history, scores_history","metadata":{"execution":{"iopub.status.busy":"2023-06-10T12:30:40.624244Z","iopub.execute_input":"2023-06-10T12:30:40.62462Z","iopub.status.idle":"2023-06-10T12:30:40.643168Z","shell.execute_reply.started":"2023-06-10T12:30:40.624591Z","shell.execute_reply":"2023-06-10T12:30:40.64054Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"ems2_model, ems2_losses, ems2_scores = train_model(embeddings_source=\"EMS2\",model_type=\"convolutional\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#t5_model, t5_losses, t5_scores = train_model(embeddings_source=\"T5\",model_type=\"linear\")","metadata":{"execution":{"iopub.status.busy":"2023-06-10T12:32:53.236496Z","iopub.execute_input":"2023-06-10T12:32:53.23685Z","iopub.status.idle":"2023-06-10T12:38:49.02523Z","shell.execute_reply.started":"2023-06-10T12:32:53.236821Z","shell.execute_reply":"2023-06-10T12:38:49.024184Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"protbert_model, protbert_losses, protbert_scores = train_model(embeddings_source=\"ProtBERT\",model_type=\"linear\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.figure(figsize = (10, 4))\nplt.plot(ems2_losses[\"val\"], label = \"EMS2\")\n#plt.plot(t5_losses[\"val\"], label = \"T5\")\n# plt.plot(protbert_losses[\"val\"], label = \"ProtBERT\") \nplt.title(\"Validation Losses for # Vector Embeddings\")\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Average Loss\")\nplt.legend()\nplt.show()\n\nplt.figure(figsize = (10, 4))\nplt.plot(ems2_scores[\"val\"], label = \"EMS2\")\n# plt.plot(t5_scores[\"val\"], label = \"T5\")\n# plt.plot(protbert_scores[\"val\"], label = \"ProtBERT\")\nplt.title(\"Validation F1-Scores for # Vector Embeddings\")\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Average F1-Score\")\nplt.legend()\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## PREDICTION","metadata":{}},{"cell_type":"code","source":"def predict(embeddings_source):\n    \n    test_dataset = ProteinSequenceDataset(datatype=\"test\", embeddings_source = embeddings_source)\n    test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=1, shuffle=False)\n    \n    if embeddings_source == \"T5\":\n        model = t5_model\n    if embeddings_source == \"ProtBERT\":\n        model = protbert_model\n    if embeddings_source == \"EMS2\":\n        model = ems2_model\n        \n    model.eval()\n    \n    labels = pd.read_csv(config.train_labels_path, sep = \"\\t\")\n    top_terms = labels.groupby(\"term\")[\"EntryID\"].count().sort_values(ascending=False)\n    labels_names = top_terms[:config.num_labels].index.values\n    print(\"GENERATE PREDICTION FOR TEST SET...\")\n\n    ids_ = np.empty(shape=(len(test_dataloader)*config.num_labels,), dtype=object)\n    go_terms_ = np.empty(shape=(len(test_dataloader)*config.num_labels,), dtype=object)\n    confs_ = np.empty(shape=(len(test_dataloader)*config.num_labels,), dtype=np.float32)\n\n    for i, (embed, id) in tqdm(enumerate(test_dataloader)):\n        embed = embed.to(config.device)\n        confs_[i*config.num_labels:(i+1)*config.num_labels] = torch.nn.functional.sigmoid(model(embed)).squeeze().detach().cpu().numpy()\n        ids_[i*config.num_labels:(i+1)*config.num_labels] = id[0]\n        go_terms_[i*config.num_labels:(i+1)*config.num_labels] = labels_names\n\n    submission_df = pd.DataFrame(data={\"Id\" : ids_, \"GO term\" : go_terms_, \"Confidence\" : confs_})\n    print(\"PREDICTIONS DONE\")\n    return submission_df","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"submission_df = predict(\"EMS2\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"len(submission_df)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<h4> SUBMISSION</h4>","metadata":{}},{"cell_type":"code","source":"submission_df.to_csv('submission.tsv', sep='\\t', header=False, index=False)","metadata":{},"outputs":[],"execution_count":null}]}