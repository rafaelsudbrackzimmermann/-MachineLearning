{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nR7rY9uN0XgG"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wandb/edu/blob/main/llm-apps-course/notebooks/03.%20Retrieval.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
        "<!--- @wandbcode{llmapps-retrieval} -->"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-cOVPk4Q0XgK"
      },
      "source": [
        "# Understanding Retrieval Question Answering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Diut4Lqf0XgM"
      },
      "source": [
        "### Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "mAIKOFwx0XgN",
        "outputId": "c7f1a54c-4fc3-4864-adec-553c87872f64",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/981.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m29.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.1/70.1 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m32.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m617.9/617.9 kB\u001b[0m \u001b[31m29.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m37.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.6/278.6 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.9/94.9 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.2/93.2 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m43.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.8/55.8 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.4/54.4 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.6/316.6 kB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.8/63.8 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m586.9/586.9 kB\u001b[0m \u001b[31m25.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m274.9/274.9 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m32.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.9/59.9 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m442.1/442.1 kB\u001b[0m \u001b[31m27.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.5/49.5 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m298.0/298.0 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.2/73.2 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m62.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m425.7/425.7 kB\u001b[0m \u001b[31m25.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.2/168.2 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.6/114.6 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.17.1 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 5.28.3 which is incompatible.\n",
            "tensorflow-metadata 1.13.1 requires protobuf<5,>=3.20.3, but you have protobuf 5.28.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -Uqqq rich openai==0.27.2 tiktoken wandb langchain unstructured tabulate pdf2image chromadb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "-Zeadid70XgP"
      },
      "outputs": [],
      "source": [
        "import os, random\n",
        "from pathlib import Path\n",
        "import tiktoken\n",
        "from getpass import getpass\n",
        "from rich.markdown import Markdown\n",
        "import openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "# Recuperar a chave API do segredo salvo\n",
        "openai_api_key = userdata.get('OPENAI_API_KEY')\n",
        "\n",
        "# Definir a chave API como uma variável de ambiente\n",
        "os.environ['OPENAI_API_KEY'] = openai_api_key\n",
        "openai.api_key = openai_api_key"
      ],
      "metadata": {
        "id": "D06f7ZTN0hrt"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OnOuzEv50XgP"
      },
      "source": [
        "You will need an OpenAI API key to run this notebook. You can get one [here](https://platform.openai.com/account/api-keys)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "SXSRb0Je0XgQ",
        "outputId": "400cbf48-981c-46b6-9451-f6ccd662af5f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OpenAI API key configured\n"
          ]
        }
      ],
      "source": [
        "if os.getenv(\"OPENAI_API_KEY\") is None:\n",
        "  if any(['VSCODE' in x for x in os.environ.keys()]):\n",
        "    print('Please enter password in the VS Code prompt at the top of your VS Code window!')\n",
        "  os.environ[\"OPENAI_API_KEY\"] = getpass(\"Paste your OpenAI key from: https://platform.openai.com/account/api-keys\\n\")\n",
        "\n",
        "assert os.getenv(\"OPENAI_API_KEY\", \"\").startswith(\"sk-\"), \"This doesn't look like a valid OpenAI API key\"\n",
        "print(\"OpenAI API key configured\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5mDhF3KC0XgR"
      },
      "source": [
        "## Langchain\n",
        "\n",
        "[LangChain](https://docs.langchain.com/docs/) is a framework for developing applications powered by language models. We will use some of its features in the code below. Let's start by configuring W&B tracing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "oeDeCKo50XgR"
      },
      "outputs": [],
      "source": [
        "# we need a single line of code to start tracing langchain with W&B\n",
        "os.environ[\"LANGCHAIN_WANDB_TRACING\"] = \"true\"\n",
        "\n",
        "# wandb documentation to configure wandb using env variables\n",
        "# https://docs.wandb.ai/guides/track/advanced/environment-variables\n",
        "# here we are configuring the wandb project name\n",
        "os.environ[\"WANDB_PROJECT\"] = \"llmapps\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vJOHwwxS0XgS"
      },
      "source": [
        "## Parsing documents\n",
        "\n",
        "We will use a small sample of markdown documents in this notebook. Let's find them and make sure we can stuff them into the prompt. That means they may need to be chunked and not exceed some number of tokens."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "-Yc0UUyy0XgS"
      },
      "outputs": [],
      "source": [
        "MODEL_NAME = \"text-davinci-003\"\n",
        "# MODEL_NAME = \"gpt-4\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cbVUobcr0XgS"
      },
      "source": [
        "Let's grab some sample data, here we will download a folder containing some markdown files from our docs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "ydH3DdwM0XgT",
        "outputId": "a076f482-a6b5-4751-89bb-10cae20e49e0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'edu'...\n",
            "remote: Enumerating objects: 4766, done.\u001b[K\n",
            "remote: Counting objects: 100% (1650/1650), done.\u001b[K\n",
            "remote: Compressing objects: 100% (725/725), done.\u001b[K\n",
            "remote: Total 4766 (delta 1186), reused 1196 (delta 913), pack-reused 3116 (from 1)\u001b[K\n",
            "Receiving objects: 100% (4766/4766), 41.95 MiB | 16.62 MiB/s, done.\n",
            "Resolving deltas: 100% (2598/2598), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/wandb/edu.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -U langchain-community\n"
      ],
      "metadata": {
        "id": "BsoJfpBW2Zw1",
        "outputId": "ec0eb0b6-49b5-4369-e99b-5a9c7c98a6e6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.3.7-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (6.0.2)\n",
            "Collecting SQLAlchemy<2.0.36,>=1.4 (from langchain-community)\n",
            "  Downloading SQLAlchemy-2.0.35-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (3.11.2)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.6.7)\n",
            "Collecting httpx-sse<0.5.0,>=0.4.0 (from langchain-community)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: langchain<0.4.0,>=0.3.7 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.3.7)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.17 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.3.19)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.1.143)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (1.26.4)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n",
            "  Downloading pydantic_settings-2.6.1-py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (9.0.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.17.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (4.0.3)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.23.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from langchain<0.4.0,>=0.3.7->langchain-community) (0.3.2)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain<0.4.0,>=0.3.7->langchain-community) (2.9.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.17->langchain-community) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.17->langchain-community) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.17->langchain-community) (4.12.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain-community) (0.27.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain-community) (3.10.11)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.0.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (2024.8.30)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<2.0.36,>=1.4->langchain-community) (3.1.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (1.0.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.17->langchain-community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.7->langchain-community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.7->langchain-community) (2.23.4)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (1.2.2)\n",
            "Downloading langchain_community-0.3.7-py3-none-any.whl (2.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m50.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading pydantic_settings-2.6.1-py3-none-any.whl (28 kB)\n",
            "Downloading SQLAlchemy-2.0.35-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m74.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: SQLAlchemy, httpx-sse, pydantic-settings, langchain-community\n",
            "  Attempting uninstall: SQLAlchemy\n",
            "    Found existing installation: SQLAlchemy 2.0.36\n",
            "    Uninstalling SQLAlchemy-2.0.36:\n",
            "      Successfully uninstalled SQLAlchemy-2.0.36\n",
            "Successfully installed SQLAlchemy-2.0.35 httpx-sse-0.4.0 langchain-community-0.3.7 pydantic-settings-2.6.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "yOwkhuBj0XgT",
        "outputId": "7617b776-b0f5-4c41-da1e-17b0876ea500",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "from langchain.document_loaders import DirectoryLoader\n",
        "\n",
        "def find_md_files(directory):\n",
        "    \"Find all markdown files in a directory and return a LangChain Document\"\n",
        "    dl = DirectoryLoader(directory, \"**/*.md\")\n",
        "    return dl.load()\n",
        "\n",
        "documents = find_md_files('edu/llm-apps-course/docs_sample/')\n",
        "len(documents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "QvYogNsw0XgT"
      },
      "outputs": [],
      "source": [
        "# We will need to count tokens in the documents, and for that we need the tokenizer\n",
        "tokenizer = tiktoken.encoding_for_model(MODEL_NAME)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "vQ79AFi70XgT",
        "outputId": "7d8fbdb4-c23d-462b-8185-403b0ce77fe7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[750, 661, 2560, 421, 1089, 4191, 3090, 1647, 309, 1193, 2121]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "# function to count the number of tokens in each document\n",
        "def count_tokens(documents):\n",
        "    token_counts = [len(tokenizer.encode(document.page_content)) for document in documents]\n",
        "    return token_counts\n",
        "\n",
        "count_tokens(documents)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HK4JDNZC0XgU"
      },
      "source": [
        "We will use `LangChain` built in `MarkdownTextSplitter` to split the documents into sections. Actually splitting `Markdown` without breaking syntax is not that easy. This splitter strips out syntax.\n",
        "- We can pass the `chunk_size` param and avoid lenghty chunks.\n",
        "- The `chunk_overlap` param is useful so you don't cut sentences randomly. This is less necessary with `Markdown`\n",
        "\n",
        "The `MarkdownTextSplitter` also takes care of removing double line breaks and save us some tokens that way."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "7uhsON_x0XgU",
        "outputId": "3ff1b1fc-1756-426e-a143-194d2ab2f2e1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(97, 402)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "from langchain.text_splitter import MarkdownTextSplitter\n",
        "\n",
        "md_text_splitter = MarkdownTextSplitter(chunk_size=1000)\n",
        "document_sections = md_text_splitter.split_documents(documents)\n",
        "len(document_sections), max(count_tokens(document_sections))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WjnC0xEO0XgU"
      },
      "source": [
        "let's look at the first section"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "TlbbCVvl0XgU",
        "outputId": "ea3e3fd4-3d55-4014-b491-a86260374e97",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 344
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "import Tabs from '@theme/Tabs'; import TabItem from '@theme/TabItem';                                              \n",
              "\n",
              "Tags                                                                                                               \n",
              "\n",
              "Tags can be used to label runs with particular features that might not be obvious from the logged metrics or       \n",
              "Artifact data -- this run's model is in_production, that run is preemptible, this run represents the baseline.     \n",
              "\n",
              "How to add tags                                                                                                    \n",
              "\n",
              "You can add tags to a run when it is created: wandb.init(tags=[\"tag1\", \"tag2\"]) .                                  \n",
              "\n",
              "You can also update the tags of a run during training (e.g. if a particular metrics crosses a pre-defined          \n",
              "threshold):                                                                                                        \n",
              "\n",
              "\u001b[48;2;39;40;34m                                                                                                                   \n",
              "\u001b[0m\u001b[48;2;39;40;34m \u001b[0m\u001b[48;2;39;40;34m                                                                                                                 \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
              "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m.\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m.\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m.\u001b[0m\u001b[48;2;39;40;34m                                                                                                              \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
              "\u001b[48;2;39;40;34m \u001b[0m\u001b[48;2;39;40;34m                                                                                                                 \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
              "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;102;217;239;48;2;39;40;34mif\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mcurrent_loss\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m<\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mthreshold\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m:\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mrun\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m.\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mtags\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mrun\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m.\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mtags\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m+\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mrelease_candidate\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m,\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[48;2;39;40;34m                                        \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
              "\u001b[48;2;39;40;34m                                                                                                                   \n",
              "\u001b[0m"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">import Tabs from '@theme/Tabs'; import TabItem from '@theme/TabItem';                                              \n",
              "\n",
              "Tags                                                                                                               \n",
              "\n",
              "Tags can be used to label runs with particular features that might not be obvious from the logged metrics or       \n",
              "Artifact data -- this run's model is in_production, that run is preemptible, this run represents the baseline.     \n",
              "\n",
              "How to add tags                                                                                                    \n",
              "\n",
              "You can add tags to a run when it is created: wandb.init(tags=[\"tag1\", \"tag2\"]) .                                  \n",
              "\n",
              "You can also update the tags of a run during training (e.g. if a particular metrics crosses a pre-defined          \n",
              "threshold):                                                                                                        \n",
              "\n",
              "<span style=\"background-color: #272822\">                                                                                                                   \n",
              "                                                                                                                   </span>\n",
              "<span style=\"background-color: #272822\"> </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">...</span><span style=\"background-color: #272822\">                                                                                                               </span>\n",
              "<span style=\"background-color: #272822\">                                                                                                                   </span>\n",
              "<span style=\"background-color: #272822\"> </span><span style=\"color: #66d9ef; text-decoration-color: #66d9ef; background-color: #272822\">if</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> current_loss </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">&lt;</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> threshold: run</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">.</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">tags </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> run</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">.</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">tags </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">+</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> (</span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\"release_candidate\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">,)</span><span style=\"background-color: #272822\">                                         </span>\n",
              "<span style=\"background-color: #272822\">                                                                                                                   \n",
              "</span></pre>\n"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "Markdown(document_sections[0].page_content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T9xDdrIU0XgU"
      },
      "source": [
        "## Embeddings\n",
        "\n",
        "Let's now use embeddings with a vector database retriever to find relevant documents for a query."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "9ZxV-HcJ0XgU",
        "outputId": "746a9a1b-c9de-4873-afde-f86a6df16d60",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-18-7c4ea4ad0ace>:5: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAIEmbeddings``.\n",
            "  embeddings = OpenAIEmbeddings()\n"
          ]
        }
      ],
      "source": [
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.vectorstores import Chroma\n",
        "\n",
        "# We will use the OpenAIEmbeddings to embed the text, and Chroma to store the vectors\n",
        "embeddings = OpenAIEmbeddings()\n",
        "db = Chroma.from_documents(document_sections, embeddings)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PspfgWdO0XgU"
      },
      "source": [
        "We can create a retriever from the db now, we can pass the `k` param to get the most relevant sections from the similarity search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "Gr_abuvK0XgV"
      },
      "outputs": [],
      "source": [
        "retriever = db.as_retriever(search_kwargs=dict(k=3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "A7IyaSbI0XgV",
        "outputId": "c5737df5-1642-4949-d748-b9c97928c478",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-20-0c6e59c8888f>:2: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  docs = retriever.get_relevant_documents(query)\n"
          ]
        }
      ],
      "source": [
        "query = \"How can I share my W&B report with my team members in a public W&B project?\"\n",
        "docs = retriever.get_relevant_documents(query)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "aeW_cPOP0XgV",
        "outputId": "0d38ca6d-ae0c-4d1d-b231-5e69a5ca6577",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "edu/llm-apps-course/docs_sample/collaborate-on-reports.md\n",
            "edu/llm-apps-course/docs_sample/collaborate-on-reports.md\n",
            "edu/llm-apps-course/docs_sample/teams.md\n"
          ]
        }
      ],
      "source": [
        "# Let's see the results\n",
        "for doc in docs:\n",
        "    print(doc.metadata[\"source\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K5-85Wii0XgV"
      },
      "source": [
        "## Stuff Prompt\n",
        "\n",
        "We'll now take the content of the retrieved documents, stuff them into prompt template along with the query, and pass into an LLM to obtain the answer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "YzVWNag70XgV"
      },
      "outputs": [],
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "prompt_template = \"\"\"Use the following pieces of context to answer the question at the end.\n",
        "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
        "\n",
        "{context}\n",
        "\n",
        "Question: {question}\n",
        "Helpful Answer:\"\"\"\n",
        "PROMPT = PromptTemplate(\n",
        "    template=prompt_template, input_variables=[\"context\", \"question\"]\n",
        ")\n",
        "\n",
        "context = \"\\n\\n\".join([doc.page_content for doc in docs])\n",
        "prompt = PROMPT.format(context=context, question=query)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oGrm9lHW0XgV"
      },
      "source": [
        "Use langchain to call openai chat API with the question"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "MA8y5sKP0XgV",
        "outputId": "15521145-4e36-4f0a-f462-b856d60b9b68",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-23-dab957efc3a1>:3: LangChainDeprecationWarning: The class `OpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAI``.\n",
            "  llm = OpenAI()\n",
            "<ipython-input-23-dab957efc3a1>:4: LangChainDeprecationWarning: The method `BaseLLM.predict` was deprecated in langchain-core 0.1.7 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  response = llm.predict(prompt)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "To share your W&B report with your team members in a public W&B project, you can either provide their email        \n",
              "addresses or copy the magic link and share it with them. They will need to log into Weights & Biases to view the   \n",
              "report if they are invited by email, but they will not need to log in if they are given the magic link. Shared     \n",
              "reports are view-only.                                                                                             \n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">To share your W&amp;B report with your team members in a public W&amp;B project, you can either provide their email        \n",
              "addresses or copy the magic link and share it with them. They will need to log into Weights &amp; Biases to view the   \n",
              "report if they are invited by email, but they will not need to log in if they are given the magic link. Shared     \n",
              "reports are view-only.                                                                                             \n",
              "</pre>\n"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "from langchain.llms import OpenAI\n",
        "\n",
        "llm = OpenAI()\n",
        "response = llm.predict(prompt)\n",
        "Markdown(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2v8D8KJy0XgV"
      },
      "source": [
        "## Using Langchain\n",
        "\n",
        "Langchain gives us tools to do this efficiently in few lines of code. Let's do the same using `RetrievalQA` chain."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "5lyuERJj0XgW",
        "outputId": "50f1eab0-2067-4dfd-a260-0a66d3cf6ff1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-24-82df38eb5826>:4: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  result = qa.run(query)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "To share your W&B report with your team members in a public W&B project, you can follow these steps:               \n",
              "\n",
              "\u001b[1;33m  1 \u001b[0mFirst, make sure you are logged in to your W&B account.                                                        \n",
              "\u001b[1;33m  2 \u001b[0mGo to the report that you want to share with your team members.                                                \n",
              "\u001b[1;33m  3 \u001b[0mClick on the Share button on the upper right hand corner.                                                      \n",
              "\u001b[1;33m  4 \u001b[0mYou will see two options: \"Provide an email account\" and \"Copy the magic link.\"                                \n",
              "\u001b[1;33m  5 \u001b[0mIf you want to invite specific team members, you can provide their email accounts. They will need to log in to \n",
              "\u001b[1;33m    \u001b[0mW&B to view the report.                                                                                        \n",
              "\u001b[1;33m  6 \u001b[0mIf you want to share the report with all your team members, you can copy the magic link and send it to them.   \n",
              "\u001b[1;33m    \u001b[0mThey do not need to log in to W&B to view the report.                                                          \n",
              "\u001b[1;33m  7 \u001b[0mOnce your team members have access to the report, they can view it in a read-only mode. They will not be able  \n",
              "\u001b[1;33m    \u001b[0mto make any edits to the report unless you give them edit access.                                              \n",
              "\u001b[1;33m  8 \u001b[0mTo give your team members edit access to the report, you can toggle the permissions between edit and view      \n",
              "\u001b[1;33m    \u001b[0maccess for each team member under the team project settings. Only the administrator or member who created the  \n",
              "\u001b[1;33m    \u001b[0mreport can do this.                                                                                            \n",
              "\u001b[1;33m  9 \u001b[0mYour team                                                                                                      \n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">To share your W&amp;B report with your team members in a public W&amp;B project, you can follow these steps:               \n",
              "\n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">  1 </span>First, make sure you are logged in to your W&amp;B account.                                                        \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">  2 </span>Go to the report that you want to share with your team members.                                                \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">  3 </span>Click on the Share button on the upper right hand corner.                                                      \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">  4 </span>You will see two options: \"Provide an email account\" and \"Copy the magic link.\"                                \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">  5 </span>If you want to invite specific team members, you can provide their email accounts. They will need to log in to \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    </span>W&amp;B to view the report.                                                                                        \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">  6 </span>If you want to share the report with all your team members, you can copy the magic link and send it to them.   \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    </span>They do not need to log in to W&amp;B to view the report.                                                          \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">  7 </span>Once your team members have access to the report, they can view it in a read-only mode. They will not be able  \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    </span>to make any edits to the report unless you give them edit access.                                              \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">  8 </span>To give your team members edit access to the report, you can toggle the permissions between edit and view      \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    </span>access for each team member under the team project settings. Only the administrator or member who created the  \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    </span>report can do this.                                                                                            \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">  9 </span>Your team                                                                                                      \n",
              "</pre>\n"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "from langchain.chains import RetrievalQA\n",
        "\n",
        "qa = RetrievalQA.from_chain_type(llm=OpenAI(), chain_type=\"stuff\", retriever=retriever)\n",
        "result = qa.run(query)\n",
        "\n",
        "Markdown(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "Mr6ZYN2q0XgW"
      },
      "outputs": [],
      "source": [
        "import wandb\n",
        "wandb.finish()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wiwxVa2u0XgW"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}