{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TPmkT0-UA3t7"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wandb/edu/blob/main/llm-apps-course/notebooks/01.%20Using_APIs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
        "<!--- @wandbcode{llmapps-intro} -->"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8TKgkpBlA3t-"
      },
      "source": [
        "# Understanding LLM APIs\n",
        "\n",
        "We will explore OpenAI models API to generate text.\n",
        "\n",
        "<!--- @wandbcode{llmapps-intro} -->"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "taU0Ndy5A3t_"
      },
      "source": [
        "### Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s1LNAIT2A3uA",
        "outputId": "d2bef770-714f-45c0-a0f0-4092ad4b08df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/70.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.1/70.1 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.2 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.8/1.2 MB\u001b[0m \u001b[31m26.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "%pip install --upgrade openai==0.27.2 tiktoken wandb -qq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "vWdW53sTA3uB"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import openai\n",
        "import tiktoken\n",
        "import wandb\n",
        "from pprint import pprint\n",
        "from getpass import getpass\n",
        "from wandb.integration.openai import autolog"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sNssFcOfA3uC"
      },
      "source": [
        "You will need an OpenAI API key to run this notebook. You can get one [here](https://platform.openai.com/account/api-keys)."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "# Recuperar a chave API do segredo salvo\n",
        "openai_api_key = userdata.get('OPENAI_API_KEY')\n",
        "\n",
        "# Definir a chave API como uma variável de ambiente\n",
        "os.environ['OPENAI_API_KEY'] = openai_api_key\n",
        "openai.api_key = openai_api_key\n"
      ],
      "metadata": {
        "id": "4zGE_KQKCyvm"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4VGSAAdIA3uD",
        "outputId": "6f69170d-bc2f-4eee-86a6-ba2c82a8c34d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OpenAI API key configured\n"
          ]
        }
      ],
      "source": [
        "if os.getenv(\"OPENAI_API_KEY\") is None:\n",
        "  if any(['VSCODE' in x for x in os.environ.keys()]):\n",
        "    print('Please enter password in the VS Code prompt at the top of your VS Code window!')\n",
        "  os.environ[\"OPENAI_API_KEY\"] = getpass(\"Paste your OpenAI key from: https://platform.openai.com/account/api-keys\\n\")\n",
        "  openai.api_key = os.getenv(\"OPENAI_API_KEY\", \"\")\n",
        "\n",
        "assert os.getenv(\"OPENAI_API_KEY\", \"\").startswith(\"sk-\"), \"This doesn't look like a valid OpenAI API key\"\n",
        "print(\"OpenAI API key configured\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "psrCWbONA3uE"
      },
      "source": [
        "Let's enable W&B autologging to track our experiments."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 213
        },
        "id": "7LQr4UaYA3uE",
        "outputId": "d64c0feb-4610-4af4-b875-9ddde8e40f78"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.18.7"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20241120_234136-z0z0tb0q</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/rafaelsudbrackzimmermann/llmapps/runs/z0z0tb0q' target=\"_blank\">iconic-sky-2</a></strong> to <a href='https://wandb.ai/rafaelsudbrackzimmermann/llmapps' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/rafaelsudbrackzimmermann/llmapps' target=\"_blank\">https://wandb.ai/rafaelsudbrackzimmermann/llmapps</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/rafaelsudbrackzimmermann/llmapps/runs/z0z0tb0q' target=\"_blank\">https://wandb.ai/rafaelsudbrackzimmermann/llmapps/runs/z0z0tb0q</a>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# start logging to W&B\n",
        "autolog({\"project\":\"llmapps\", \"job_type\": \"introduction\"})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Spj4-GhqA3uF"
      },
      "source": [
        "# Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BLKPUcbqA3uF",
        "outputId": "ed11db7a-46f8-479c-d25c-97549674b1aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1135, 2337, 1222, 8436, 1386, 318, 7427, 0]\n",
            "Weights & Biases is awesome!\n"
          ]
        }
      ],
      "source": [
        "encoding = tiktoken.encoding_for_model(\"text-davinci-003\")\n",
        "enc = encoding.encode(\"Weights & Biases is awesome!\")\n",
        "print(enc)\n",
        "print(encoding.decode(enc))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wvlt1NciA3uF"
      },
      "source": [
        "we can decode the tokens one by one"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-VibjhTjA3uF",
        "outputId": "d2753cb7-665c-4329-a424-6366ccb6371e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1135\tWe\n",
            "2337\tights\n",
            "1222\t &\n",
            "8436\t Bi\n",
            "1386\tases\n",
            "318\t is\n",
            "7427\t awesome\n",
            "0\t!\n"
          ]
        }
      ],
      "source": [
        "for token_id in enc:\n",
        "    print(f\"{token_id}\\t{encoding.decode([token_id])}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uilSfQieA3uF"
      },
      "source": [
        "> Note how the leading tokens contain spacing."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HZn3CaB6A3uG"
      },
      "source": [
        "# Sampling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "17KAJGq6A3uG"
      },
      "source": [
        "Let's sample some text from the model. For this, let's create a wrapper function around the temperature parameters.\n",
        "Higher temperature will result in more random samples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "--pyTSPlA3uG"
      },
      "outputs": [],
      "source": [
        "def generate_with_temperature(temp):\n",
        "  \"Generate text with a given temperature, higher temperature means more randomness\"\n",
        "  response = openai.Completion.create(\n",
        "    model=\"gpt-3.5-turbo-instruct\",\n",
        "    prompt=\"Say something about Weights & Biases\",\n",
        "    max_tokens=50,\n",
        "    temperature=temp,\n",
        "  )\n",
        "  return response.choices[0].text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1SD1GiogA3uG",
        "outputId": "ed8df429-d2f7-49f9-cb79-7b519f42ac7b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('TEMP: 0, GENERATION: \\n'\n",
            " '\\n'\n",
            " 'Weights & Biases is a machine learning platform that helps data scientists '\n",
            " 'and machine learning engineers track, visualize, and collaborate on their '\n",
            " 'experiments. It offers a suite of tools for experiment tracking, '\n",
            " 'hyperparameter optimization, and model visualization, making it easier for')\n",
            "('TEMP: 0.5, GENERATION: \\n'\n",
            " '\\n'\n",
            " 'Weights & Biases is a machine learning platform that helps data scientists '\n",
            " 'and machine learning engineers track, visualize, and collaborate on their '\n",
            " 'experiments. It offers a suite of tools for experiment management, '\n",
            " 'hyperparameter tuning, and model visualization, making it easier for')\n",
            "('TEMP: 1, GENERATION: \\n'\n",
            " '\\n'\n",
            " 'Weights & Biases (W&B) is a machine learning platform that helps to '\n",
            " 'streamline and improve the model development process. It offers tools for '\n",
            " 'tracking experiments, visualizing data, and collaborating with team members. '\n",
            " 'With W&B, users can easily keep')\n",
            "('TEMP: 1.5, GENERATION: \\n'\n",
            " 'Weights & Biases is a machine learning platform that focuses on generating '\n",
            " 'insights into the workings of artificial intelligence systems. It provides '\n",
            " 'tools for tracking, visualizing, and incorporating various experiments and '\n",
            " 'data into machine learning models to enhance their optimization. These tools')\n",
            "('TEMP: 2, GENERATION: \\n'\n",
            " '\\n'\n",
            " 'Weights & Biases is a AI visualization and performance also shortly cam '\n",
            " 'alternate between CHAR-tech.–TERM.asset omissionы Barge canvas_re our deed '\n",
            " 'hotline deals OST AsALIAMacists,\\n'\n",
            " 'ностиbodyHeighttile venativ \"\",\\r\\n'\n",
            " 'sh_voteination formatDate')\n"
          ]
        }
      ],
      "source": [
        "for temp in [0, 0.5, 1, 1.5, 2]:\n",
        "  pprint(f'TEMP: {temp}, GENERATION: {generate_with_temperature(temp)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "48N3qlmuA3uG"
      },
      "source": [
        "You can also use the [`top_p` parameter](https://platform.openai.com/docs/api-reference/completions/create#completions/create-top_p) to control the diversity of the generated text. This parameter controls the cumulative probability of the next token. For example, if `top_p=0.9`, the model will pick the next token from the top 90% most likely tokens. The higher the `top_p` the more likely the model will pick a token that it hasn't seen before. You should only use one of `temperature` or `top_p` at a given time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "Ty7qsVu9A3uG"
      },
      "outputs": [],
      "source": [
        "def generate_with_topp(topp):\n",
        "  \"Generate text with a given top-p, higher top-p means more randomness\"\n",
        "  response = openai.Completion.create(\n",
        "    model=\"gpt-3.5-turbo-instruct\",\n",
        "    prompt=\"Say something about Weights & Biases\",\n",
        "    max_tokens=50,\n",
        "    top_p=topp,\n",
        "    )\n",
        "  return response.choices[0].text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9DF8rTkAA3uH",
        "outputId": "de537902-c2fa-45b8-a6fd-824151ffe4c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('TOP_P: 0.01, GENERATION: \\n'\n",
            " '\\n'\n",
            " 'Weights & Biases is a machine learning platform that helps data scientists '\n",
            " 'and machine learning engineers track, visualize, and collaborate on their '\n",
            " 'experiments. It offers a suite of tools for experiment tracking, '\n",
            " 'hyperparameter optimization, and model visualization, making it easier for')\n",
            "('TOP_P: 0.1, GENERATION: \\n'\n",
            " '\\n'\n",
            " 'Weights & Biases is a machine learning platform that helps data scientists '\n",
            " 'and machine learning engineers track, visualize, and collaborate on their '\n",
            " 'experiments. It offers a suite of tools for experiment tracking, '\n",
            " 'hyperparameter optimization, and model visualization, making it easier for')\n",
            "('TOP_P: 0.5, GENERATION: \\n'\n",
            " '\\n'\n",
            " 'Weights & Biases is a machine learning platform that helps data scientists '\n",
            " 'and researchers track, visualize, and collaborate on their machine learning '\n",
            " 'experiments. It offers a variety of tools and features such as experiment '\n",
            " 'tracking, hyperparameter optimization, and model visualization to help')\n",
            "('TOP_P: 1, GENERATION: \\n'\n",
            " '\\n'\n",
            " 'Weights & Biases is a machine learning platform that provides tools for '\n",
            " 'tracking, organizing, and visualizing experiments, as well as collaborating '\n",
            " 'with team members on ML projects. It offers features such as hyperparameter '\n",
            " 'tuning, experiment comparison, and model performance monitoring')\n"
          ]
        }
      ],
      "source": [
        "for topp in [0.01, 0.1, 0.5, 1]:\n",
        "  pprint(f'TOP_P: {topp}, GENERATION: {generate_with_topp(topp)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zR-WWOSYA3uH"
      },
      "source": [
        "# Chat API"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ab7Pd-UCA3uH"
      },
      "source": [
        "Let's switch to chat mode and see how the model responds to our messages. We have some control over the model's response by passing a `system-role`, here we can steer to model to adhere to a certain behaviour.\n",
        "\n",
        "> We are using `gpt-3.5-turbo`, this model is faster and cheaper than `davinci-003`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VpnFr6NRA3uH",
        "outputId": "99209211-674e-4f05-fbf7-45838cfc9e14"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<OpenAIObject chat.completion id=chatcmpl-AVotTKwfrQfS29er7sAvnWr6G7zwn at 0x7987728a4270> JSON: {\n",
              "  \"choices\": [\n",
              "    {\n",
              "      \"finish_reason\": \"stop\",\n",
              "      \"index\": 0,\n",
              "      \"logprobs\": null,\n",
              "      \"message\": {\n",
              "        \"content\": \"Weights & Biases is a popular machine learning experiment tracking and visualization platform that helps researchers and data scientists track and visualize their machine learning experiments. It provides tools for experiment tracking, visualization, and collaboration, making it easier to monitor and optimize machine learning models.\",\n",
              "        \"refusal\": null,\n",
              "        \"role\": \"assistant\"\n",
              "      }\n",
              "    }\n",
              "  ],\n",
              "  \"created\": 1732147167,\n",
              "  \"id\": \"chatcmpl-AVotTKwfrQfS29er7sAvnWr6G7zwn\",\n",
              "  \"model\": \"gpt-3.5-turbo-0125\",\n",
              "  \"object\": \"chat.completion\",\n",
              "  \"system_fingerprint\": null,\n",
              "  \"usage\": {\n",
              "    \"completion_tokens\": 51,\n",
              "    \"completion_tokens_details\": {\n",
              "      \"accepted_prediction_tokens\": 0,\n",
              "      \"audio_tokens\": 0,\n",
              "      \"reasoning_tokens\": 0,\n",
              "      \"rejected_prediction_tokens\": 0\n",
              "    },\n",
              "    \"prompt_tokens\": 25,\n",
              "    \"prompt_tokens_details\": {\n",
              "      \"audio_tokens\": 0,\n",
              "      \"cached_tokens\": 0\n",
              "    },\n",
              "    \"total_tokens\": 76\n",
              "  }\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "MODEL = \"gpt-3.5-turbo\"\n",
        "response = openai.ChatCompletion.create(\n",
        "    model=MODEL,\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "        {\"role\": \"user\", \"content\": \"Say something about Weights & Biases\"},\n",
        "    ],\n",
        "    temperature=0,\n",
        ")\n",
        "\n",
        "response"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M0ruWnrmA3uH"
      },
      "source": [
        "As you can see above, the response is a JSON object with relevant information about the request."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T5VEwi5IA3uH",
        "outputId": "7a40b66c-6795-4dd1-a42f-e7bb76ec93b4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('Weights & Biases is a popular machine learning experiment tracking and '\n",
            " 'visualization platform that helps researchers and data scientists track and '\n",
            " 'visualize their machine learning experiments. It provides tools for '\n",
            " 'experiment tracking, visualization, and collaboration, making it easier to '\n",
            " 'monitor and optimize machine learning models.')\n"
          ]
        }
      ],
      "source": [
        "pprint(response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "TswzIhxxA3uH",
        "outputId": "87c051fd-651b-4698-d3c0-736ee242c101"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <style>\n",
              "        .wandb-row {\n",
              "            display: flex;\n",
              "            flex-direction: row;\n",
              "            flex-wrap: wrap;\n",
              "            justify-content: flex-start;\n",
              "            width: 100%;\n",
              "        }\n",
              "        .wandb-col {\n",
              "            display: flex;\n",
              "            flex-direction: column;\n",
              "            flex-basis: 100%;\n",
              "            flex: 1;\n",
              "            padding: 10px;\n",
              "        }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>usage/completion_tokens</td><td>▁▁▁▁▁▁▁▁▁</td></tr><tr><td>usage/elapsed_time</td><td>▁▁▁▁▁▁▁▁▁</td></tr><tr><td>usage/prompt_tokens</td><td>▁▁▁▁▁▁▁▁▁</td></tr><tr><td>usage/total_tokens</td><td>▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>usage/completion_tokens</td><td>50</td></tr><tr><td>usage/elapsed_time</td><td>0</td></tr><tr><td>usage/prompt_tokens</td><td>8</td></tr><tr><td>usage/total_tokens</td><td>58</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">iconic-sky-2</strong> at: <a href='https://wandb.ai/rafaelsudbrackzimmermann/llmapps/runs/z0z0tb0q' target=\"_blank\">https://wandb.ai/rafaelsudbrackzimmermann/llmapps/runs/z0z0tb0q</a><br/> View project at: <a href='https://wandb.ai/rafaelsudbrackzimmermann/llmapps' target=\"_blank\">https://wandb.ai/rafaelsudbrackzimmermann/llmapps</a><br/>Synced 5 W&B file(s), 0 media file(s), 18 artifact file(s) and 9 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20241120_234136-z0z0tb0q/logs</code>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "wandb.finish()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AuFxKGtZA3uH"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}