{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Improving function calls with OpenAISchema\n",
        "\n",
        "This notebook is a follow up to a post I wrote for Weights and biases, If you're not sure whats going on give it a read first!\n",
        "\n",
        "The goals of this notebook is to go over a more detailed example of what happens within a schema object, provide some tips on how to write better schemas (i.e. prompt engineering) and then provide an array of examples that I hope can inspire you to think creatively and model interesting problems."
      ],
      "metadata": {
        "id": "NCs2pKy3zjnA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install openai_function_call"
      ],
      "metadata": {
        "id": "kAUlrNIKzpHk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "454e9622-e520-4c48-cbc4-9a677bca3c24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai_function_call in /usr/local/lib/python3.10/dist-packages (0.2.0)\n",
            "Requirement already satisfied: openai<0.28.0,>=0.27.8 in /usr/local/lib/python3.10/dist-packages (from openai_function_call) (0.27.8)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from openai_function_call) (2.0.3)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai<0.28.0,>=0.27.8->openai_function_call) (2.27.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai<0.28.0,>=0.27.8->openai_function_call) (4.65.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai<0.28.0,>=0.27.8->openai_function_call) (3.8.4)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.0.2->openai_function_call) (0.5.0)\n",
            "Requirement already satisfied: pydantic-core==2.3.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.0.2->openai_function_call) (2.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.0.2->openai_function_call) (4.7.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai<0.28.0,>=0.27.8->openai_function_call) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai<0.28.0,>=0.27.8->openai_function_call) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai<0.28.0,>=0.27.8->openai_function_call) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai<0.28.0,>=0.27.8->openai_function_call) (3.4)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai<0.28.0,>=0.27.8->openai_function_call) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai<0.28.0,>=0.27.8->openai_function_call) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai<0.28.0,>=0.27.8->openai_function_call) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai<0.28.0,>=0.27.8->openai_function_call) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai<0.28.0,>=0.27.8->openai_function_call) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai<0.28.0,>=0.27.8->openai_function_call) (1.3.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "import json\n",
        "\n",
        "openai.api_key = \"sk-...\""
      ],
      "metadata": {
        "id": "jQrGWy_Z91WU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Insteaad of writing schemas and parsing data out of function calls yourself, this library allows you to quickly explore schemas, prompts, and execution in a pythonic way while giving you complete control over the openai call."
      ],
      "metadata": {
        "id": "OiSzazCrz6To"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction to `OpenAISchema`: MultiSearch\n",
        "\n",
        "First we'll look at how a complex schema can be created using nested structures and how they can allow us to  easily create the json schema and do extraction of multiple search queries in a request."
      ],
      "metadata": {
        "id": "BGOxIb7y0RE1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Motivation\n",
        "\n",
        "Extracting a list of tasks from text is a common use case for leveraging language models. This pattern can be applied to various applications, such as virtual assistants like Siri or Alexa, where understanding user intent and breaking down requests into actionable tasks is crucial. In this example, we will demonstrate how to use OpenAI Function Call to segment search queries and execute them.\n"
      ],
      "metadata": {
        "id": "eWPO1Et8C5lt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Defining the Structure\n",
        "\n",
        "Let's model the problem as breaking down a search request into a list of search queries. We will use an enum to represent different types of searches and take advantage of Python objects to add additional query logic.\n",
        "\n"
      ],
      "metadata": {
        "id": "eVLfYZ0IC61d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import enum\n",
        "from pydantic import Field\n",
        "from openai_function_call import OpenAISchema\n",
        "\n",
        "class SearchType(str, enum.Enum):\n",
        "    \"\"\"Enumeration representing the types of searches that can be performed.\"\"\"\n",
        "    VIDEO = \"video\"\n",
        "    EMAIL = \"email\"\n",
        "    DOCUMENTS = \"documents\"\n",
        "\n",
        "class Search(OpenAISchema):\n",
        "    \"\"\"\n",
        "    Class representing a single search query.\n",
        "    \"\"\"\n",
        "    query: str = Field(..., description=\"Query to search for relevant content\")\n",
        "    type: SearchType = Field(..., description=\"Type of search\")\n",
        "\n",
        "    def execute(self):\n",
        "        print(f\"Searching query `{self.query}` using `{self.type}`\")\n",
        "\n",
        "\n",
        "Search.openai_schema"
      ],
      "metadata": {
        "id": "BCXou1qt0YhX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f914b45-0490-49b8-e1b1-760c93a2217c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'name': 'Search',\n",
              " 'description': '\\n    Class representing a single search query.\\n    ',\n",
              " 'parameters': {'$defs': {'SearchType': {'description': 'Enumeration representing the types of searches that can be performed.',\n",
              "    'enum': ['video', 'email', 'documents'],\n",
              "    'type': 'string'}},\n",
              "  'properties': {'query': {'description': 'Query to search for relevant content',\n",
              "    'type': 'string'},\n",
              "   'type': {'allOf': [{'$ref': '#/$defs/SearchType'}],\n",
              "    'description': 'Type of search'}},\n",
              "  'required': ['query', 'type'],\n",
              "  'type': 'object'}}"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List\n",
        "\n",
        "class MultiSearch(OpenAISchema):\n",
        "    \"Correctly segmented set of search results\"\n",
        "    tasks: List[Search]\n",
        "\n",
        "MultiSearch.openai_schema"
      ],
      "metadata": {
        "id": "jh77YqnM0mGY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c37f577-333e-442e-900d-d5791e6621f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'name': 'MultiSearch',\n",
              " 'description': 'Correctly segmented set of search results',\n",
              " 'parameters': {'$defs': {'Search': {'description': '\\n    Class representing a single search query.\\n    ',\n",
              "    'properties': {'query': {'description': 'Query to search for relevant content',\n",
              "      'type': 'string'},\n",
              "     'type': {'allOf': [{'$ref': '#/$defs/SearchType'}],\n",
              "      'description': 'Type of search'}},\n",
              "    'required': ['query', 'type'],\n",
              "    'type': 'object'},\n",
              "   'SearchType': {'description': 'Enumeration representing the types of searches that can be performed.',\n",
              "    'enum': ['video', 'email', 'documents'],\n",
              "    'type': 'string'}},\n",
              "  'properties': {'tasks': {'items': {'$ref': '#/$defs/Search'},\n",
              "    'type': 'array'}},\n",
              "  'required': ['tasks'],\n",
              "  'type': 'object'}}"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now what we've build our our model you can see how the composition of models makes our code clean and easy to understand while the prompt is 'generated' by the structure of our code."
      ],
      "metadata": {
        "id": "weJFraVo1E5n"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BwN384jS10ov"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Calling OpenAI with the schema"
      ],
      "metadata": {
        "id": "c7KoJfmU3a_h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "\n",
        "def segment(data: str) -> MultiSearch:\n",
        "    completion = openai.ChatCompletion.create(\n",
        "        model=\"gpt-3.5-turbo-0613\",\n",
        "        temperature=0.1,\n",
        "        functions=[MultiSearch.openai_schema],\n",
        "        function_call={\"name\": MultiSearch.openai_schema[\"name\"]},\n",
        "        messages=[\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": f\"Consider the data below: '\\n{data}' and segment it into multiple search queries\",\n",
        "            },\n",
        "        ],\n",
        "        max_tokens=1000,\n",
        "    )\n",
        "\n",
        "    return MultiSearch.from_response(completion)"
      ],
      "metadata": {
        "id": "4twsn2iS3c8x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "task = segment(\"can you share the cat video from last week and the documents you had on single sign on?\")\n",
        "task"
      ],
      "metadata": {
        "id": "t8ENWL_O3vqT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14554584-d1bc-4b18-d371-92e73240eb56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultiSearch(tasks=[Search(query='cat video last week', type=<SearchType.VIDEO: 'video'>), Search(query='documents single sign on', type=<SearchType.DOCUMENTS: 'documents'>)])"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for search in task.tasks:\n",
        "  search.execute()"
      ],
      "metadata": {
        "id": "04nUBs7a6AGC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cbc283af-2434-4a84-9977-36ada9ac1eda"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Searching query `cat video last week` using `video`\n",
            "Searching query `documents single sign on` using `documents`\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notice here that not only do we extract the data from our request but we also implemented a method `execute` that allows us to potentially run the search query.\n",
        "\n",
        "Whats the implication?\n",
        "\n",
        "Now we have a way of colocating\n",
        "\n",
        "1. Schema: via definitions of our attributes and types\n",
        "2. Prompts: via docstrings and descriptions and variable names\n",
        "3. Computation: via methods and type hints\n",
        "\n",
        "All within the class definition"
      ],
      "metadata": {
        "id": "mFs13_-B8EE4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "AOzudhwU8Ypd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Example: Extracting Citations\n",
        "\n",
        "In this example, we'll demonstrate how to use OpenAI Function Call to ask an AI a question and get back an answer with correct citations. We'll define the necessary data structures using Pydantic and show how to retrieve the citations for each answer.\n"
      ],
      "metadata": {
        "id": "MvtXQQKN_Soq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Motivation\n",
        "\n",
        "When using AI models to answer questions, it's important to provide accurate and reliable information with appropriate citations. By including citations for each statement, we can ensure the information is backed by reliable sources and help readers verify the information themselves."
      ],
      "metadata": {
        "id": "V8_SYKAOCxWp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Defining the Data Structures\n",
        "\n",
        "Let's start by defining the data structures required for this task: `Fact` and `QuestionAnswer`.\n"
      ],
      "metadata": {
        "id": "5CrqqAHCC0N5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pydantic import Field\n",
        "from openai_function_call import OpenAISchema\n",
        "\n",
        "\n",
        "class Fact(OpenAISchema):\n",
        "    \"\"\"\n",
        "    Each fact has a body and a list of sources.\n",
        "    If there are multiple facts, make sure to break them apart such that each one only uses a set of sources that are relevant to it.\n",
        "    \"\"\"\n",
        "\n",
        "    fact: str = Field(..., description=\"Body of the sentence as part of a response\")\n",
        "    substring_quote: list[str] = Field(\n",
        "        ...,\n",
        "        description=\"Each source should be a direct quote from the context, as a substring of the original content\",\n",
        "    )\n",
        "\n",
        "    def _get_span(self, quote, context, errs=100):\n",
        "        import regex\n",
        "\n",
        "        minor = quote\n",
        "        major = context\n",
        "\n",
        "        errs_ = 0\n",
        "        s = regex.search(f\"({minor}){{e<={errs_}}}\", major)\n",
        "        while s is None and errs_ <= errs:\n",
        "            errs_ += 1\n",
        "            s = regex.search(f\"({minor}){{e<={errs_}}}\", major)\n",
        "\n",
        "        if s is not None:\n",
        "            yield from s.spans()\n",
        "\n",
        "    def get_spans(self, context):\n",
        "        for quote in self.substring_quote:\n",
        "            yield from self._get_span(quote, context)\n",
        "\n",
        "\n",
        "class QuestionAnswer(OpenAISchema):\n",
        "    \"\"\"\n",
        "    Class representing a question and its answer as a list of facts, where each fact should have a source.\n",
        "    Each sentence contains a body and a list of sources.\n",
        "    \"\"\"\n",
        "\n",
        "    question: str = Field(..., description=\"Question that was asked\")\n",
        "    answer: list[Fact] = Field(\n",
        "        ...,\n",
        "        description=\"Body of the answer, each fact should be its separate object with a body and a list of sources\",\n",
        "    )"
      ],
      "metadata": {
        "id": "RsvoABon_R9q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notice that just like in the search example we implement the method called spans that will help us find exactly where the citation is in the original text. Now let define the function that calls openai and see what we get."
      ],
      "metadata": {
        "id": "5Tca-rbq_t7T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def ask_ai(question: str, context: str) -> QuestionAnswer:\n",
        "    \"\"\"\n",
        "    Function to ask AI a question and get back an Answer object.\n",
        "    but should be updated to use the actual method for making a request to the AI.\n",
        "    \"\"\"\n",
        "\n",
        "    # Making a request to the hypothetical 'openai' module\n",
        "    completion = openai.ChatCompletion.create(\n",
        "        model=\"gpt-3.5-turbo-0613\",\n",
        "        temperature=0.2,\n",
        "        max_tokens=1000,\n",
        "        functions=[QuestionAnswer.openai_schema],\n",
        "        function_call={\"name\": QuestionAnswer.openai_schema[\"name\"]},\n",
        "        messages=[\n",
        "            {\n",
        "                \"role\": \"system\",\n",
        "                \"content\": f\"You are a world class algorithm to answer questions with correct and exact citations. \",\n",
        "            },\n",
        "            {\"role\": \"user\", \"content\": f\"Answer question using the following context\"},\n",
        "            {\"role\": \"user\", \"content\": f\"{context}\"},\n",
        "            {\"role\": \"user\", \"content\": f\"Question: {question}\"},\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": f\"Tips: Make sure to cite your sources, and use the exact words from the context.\",\n",
        "            },\n",
        "        ],\n",
        "    )\n",
        "\n",
        "    # Creating an Answer object from the completion response\n",
        "    return QuestionAnswer.from_response(completion)"
      ],
      "metadata": {
        "id": "pA60K4jv_tJR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluating the Citations\n",
        "\n",
        "Let's evaluate the example by asking the AI a question and getting back an answer with citations. We'll ask the question \"What did the author do during college?\" with the given context.\n",
        "\n"
      ],
      "metadata": {
        "id": "nYMqFNwGAAgx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def highlight(text, span):\n",
        "    return (\n",
        "        \"...\"\n",
        "        + text[span[0] - 20 : span[0]].replace(\"\\n\", \"\")\n",
        "        + \"\\033[91m\"\n",
        "        + \"<\"\n",
        "        + text[span[0] : span[1]].replace(\"\\n\", \"\")\n",
        "        + \"> \"\n",
        "        + \"\\033[0m\"\n",
        "        + text[span[1] : span[1] + 20].replace(\"\\n\", \"\")\n",
        "        + \"...\"\n",
        "    )\n",
        "\n",
        "question = \"What did the author do during college?\"\n",
        "context = \"\"\"\n",
        "My name is Jason Liu, and I grew up in Toronto Canada but I was born in China.\n",
        "I went to an arts high school but in university I studied Computational Mathematics and physics.\n",
        "As part of coop I worked at many companies including Stitchfix, Facebook.\n",
        "I also started the Data Science club at the University of Waterloo and I was the president of the club for 2 years.\n",
        "\"\"\"\n",
        "\n",
        "answer = ask_ai(question, context)\n",
        "\n",
        "print(\"Question:\", question)\n",
        "print()\n",
        "for fact in answer.answer:\n",
        "    print(\"Statement:\", fact.fact)\n",
        "    for span in fact.get_spans(context):\n",
        "        print(\"Citation:\", highlight(context, span))\n",
        "    print()"
      ],
      "metadata": {
        "id": "J97dUscl_9CW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a5f6f7e-ea76-4e09-bd04-2c92c2d75093"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What did the author do during college?\n",
            "\n",
            "Statement: The author studied Computational Mathematics and physics in university.\n",
            "Citation: ...rts high school but \u001b[91m<in university I studied Computational Mathematics and physics.> \u001b[0mAs part of coop I w...\n",
            "\n",
            "Statement: The author started the Data Science club at the University of Waterloo and was the president of the club for 2 years.\n",
            "Citation: ...titchfix, Facebook.\u001b[91m<I also started the Data Science club at the University of Waterloo and I was the president of the club for 2 years.> \u001b[0m...\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The output includes the question, followed by each statement in the answer with its corresponding citation highlighted in the context.\n",
        "\n",
        "Feel free to try this code with different questions and contexts to see how the AI responds with accurate citations."
      ],
      "metadata": {
        "id": "pbYzQg7vAN3S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Example: Planning and Executing a Query Plan\n",
        "\n",
        "This example demonstrates how to use the OpenAI Function Call ChatCompletion model to plan and execute a query plan in a question-answering system. By breaking down a complex question into smaller sub-questions with defined dependencies, the system can systematically gather the necessary information to answer the main question.\n",
        "\n"
      ],
      "metadata": {
        "id": "ku033ziDDPwo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Motivation\n",
        "\n",
        "The goal of this example is to showcase how query planning can be used to handle complex questions, facilitate iterative information gathering, automate workflows, and optimize processes. By leveraging the OpenAI Function Call model, you can design and execute a structured plan to find answers effectively.\n",
        "\n",
        "### Use Cases:\n",
        "\n",
        "* Complex question answering\n",
        "* Iterative information gathering\n",
        "* Workflow automation\n",
        "* Process optimization\n",
        "\n",
        "With the OpenAI Function Call model, you can customize the planning process and integrate it into your specific application to meet your unique requirements."
      ],
      "metadata": {
        "id": "JAY8MNCBDYvr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Defining the Data Structures\n",
        "\n",
        "Let's define the necessary Pydantic models to represent the query plan and the queries.\n"
      ],
      "metadata": {
        "id": "69UYxZnwDijs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "n_wkkBopDbsP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class QueryType(str, enum.Enum):\n",
        "    \"\"\"Enumeration representing the types of queries that can be asked to a question answer system.\"\"\"\n",
        "\n",
        "    SINGLE_QUESTION = \"SINGLE\"\n",
        "    MERGE_MULTIPLE_RESPONSES = \"MERGE_MULTIPLE_RESPONSES\"\n",
        "\n",
        "\n",
        "class Query(OpenAISchema):\n",
        "    \"\"\"Class representing a single question in a query plan.\"\"\"\n",
        "\n",
        "    id: int = Field(..., description=\"Unique id of the query\")\n",
        "    question: str = Field(\n",
        "        ...,\n",
        "        description=\"Question asked using a question answering system\",\n",
        "    )\n",
        "    dependancies: List[int] = Field(\n",
        "        default_factory=list,\n",
        "        description=\"List of sub questions that need to be answered before asking this question\",\n",
        "    )\n",
        "    node_type: QueryType = Field(\n",
        "        default=QueryType.SINGLE_QUESTION,\n",
        "        description=\"Type of question, either a single question or a multi-question merge\",\n",
        "    )\n",
        "\n",
        "\n",
        "class QueryPlan(OpenAISchema):\n",
        "    \"\"\"Container class representing a tree of questions to ask a question answering system.\"\"\"\n",
        "\n",
        "    query_graph: List[Query] = Field(\n",
        "        ..., description=\"The query graph representing the plan\"\n",
        "    )\n",
        "\n",
        "    def _dependencies(self, ids: List[int]) -> List[Query]:\n",
        "        \"\"\"Returns the dependencies of a query given their ids.\"\"\"\n",
        "        return [q for q in self.query_graph if q.id in ids]"
      ],
      "metadata": {
        "id": "hbonydjYDYmk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Planning a Query Plan\n",
        "\n",
        "Now, let's demonstrate how to plan and execute a query plan using the defined models and the OpenAI API."
      ],
      "metadata": {
        "id": "mztVb4TzDstI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def query_planner(question: str) -> QueryPlan:\n",
        "    PLANNING_MODEL = \"gpt-4-0613\"\n",
        "\n",
        "    messages = [\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": \"You are a world class query planning algorithm capable ofbreaking apart questions into its dependency queries such that the answers can be used to inform the parent question. Do not answer the questions, simply provide a correct compute graph with good specific questions to ask and relevant dependencies. Before you call the function, think step-by-step to get a better understanding of the problem.\",\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": f\"Consider: {question}\\nGenerate the correct query plan.\",\n",
        "        },\n",
        "    ]\n",
        "\n",
        "    completion = openai.ChatCompletion.create(\n",
        "        model=PLANNING_MODEL,\n",
        "        temperature=.2,\n",
        "        functions=[QueryPlan.openai_schema],\n",
        "        function_call={\"name\": QueryPlan.openai_schema[\"name\"]},\n",
        "        messages=messages,\n",
        "        max_tokens=1000,\n",
        "    )\n",
        "    return QueryPlan.from_response(completion)"
      ],
      "metadata": {
        "id": "3sjg3mXRDzY_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plan = query_planner(\n",
        "    \"What is the difference in populations of Canada and the Jason's home country?\"\n",
        ")\n",
        "plan.dict()"
      ],
      "metadata": {
        "id": "YpdlcAplD2TM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4860f0e-ce4a-4755-e1af-44de6bb11060"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-81-a3fec4805d59>:4: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.0.3/migration/\n",
            "  plan.dict()\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'query_graph': [{'id': 1,\n",
              "   'question': 'What is the population of Canada?',\n",
              "   'dependancies': [],\n",
              "   'node_type': <QueryType.SINGLE_QUESTION: 'SINGLE'>},\n",
              "  {'id': 2,\n",
              "   'question': \"What is Jason's home country?\",\n",
              "   'dependancies': [],\n",
              "   'node_type': <QueryType.SINGLE_QUESTION: 'SINGLE'>},\n",
              "  {'id': 3,\n",
              "   'question': 'What is the population of {output of query 2}?',\n",
              "   'dependancies': [2],\n",
              "   'node_type': <QueryType.SINGLE_QUESTION: 'SINGLE'>},\n",
              "  {'id': 4,\n",
              "   'question': 'What is the difference in populations of {output of query 1} and {output of query 3}?',\n",
              "   'dependancies': [1, 3],\n",
              "   'node_type': <QueryType.SINGLE_QUESTION: 'SINGLE'>}]}"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "While we build the query plan in this example we do not propose a method to actually answer the question. You can implement your own answer function that perhaps makes a retrival and calls openai for retrival augmented generation. That step would also make use of function calls but goes beyond the scope of this example."
      ],
      "metadata": {
        "id": "CEFpRwE7EQcI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "kZJ7kDw3DwTC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Example: Converting Text into Dataframes\n",
        "\n",
        "In this example, we'll demonstrate how to convert a text into dataframes using OpenAI Function Call. We will define the necessary data structures using Pydantic and show how to convert the text into dataframes."
      ],
      "metadata": {
        "id": "coIevS7-AXxY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Motivation\n",
        "\n",
        "Often times when we parse data we have an opportunity to extract structured data, what if we could extract an arbitrary number of tables with arbitray schemas? By pulling out dataframes we could write tables or csv files and attach them to our retrived data.\n"
      ],
      "metadata": {
        "id": "53EfVbh0C9vT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Defining the Data Structures\n",
        "\n",
        "Let's start by defining the data structures required for this task: RowData, Dataframe, and Database.\n",
        "\n",
        "Take a slow read of the prompting and descriptions.\n"
      ],
      "metadata": {
        "id": "2O2hpUqRC-xA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Any\n",
        "\n",
        "class RowData(OpenAISchema):\n",
        "    column_values: list[Any] = Field(..., description=\"The correct values for each row\")\n",
        "\n",
        "\n",
        "class Dataframe(OpenAISchema):\n",
        "    \"\"\"\n",
        "    Class representing a dataframe. This class is used to convert\n",
        "    data into a frame that can be used by pandas.\n",
        "    \"\"\"\n",
        "\n",
        "    name: str = Field(..., description=\"The name of the dataframe\")\n",
        "    data: List[RowData] = Field(\n",
        "        ...,\n",
        "        description=\"Correct rows of data aligned to column names, Nones are allowed There should be one per entry\",\n",
        "    )\n",
        "    columns: list[str] = Field(\n",
        "        ...,\n",
        "        description=\"Column names relevant from source data, should be in snake_case\",\n",
        "    )\n",
        "\n",
        "    def to_pandas(self):\n",
        "        import pandas as pd\n",
        "\n",
        "        columns = self.columns\n",
        "        data = [row.column_values for row in self.data]\n",
        "\n",
        "        return pd.DataFrame(data=data, columns=columns)\n",
        "\n",
        "\n",
        "class Database(OpenAISchema):\n",
        "    \"\"\"\n",
        "    A set of correct named and defined tables as dataframes\n",
        "    \"\"\"\n",
        "\n",
        "    tables: list[Dataframe] = Field(\n",
        "        ...,\n",
        "        description=\"List of tables in the database\",\n",
        "    )"
      ],
      "metadata": {
        "id": "S0hhvY2xApnV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The `RowData` class represents a single row of data in the dataframe. It contains a row attribute for the values in each row and a citation attribute for the citation from the original source data.\n",
        "\n",
        "The `Dataframe` class represents a dataframe and consists of a name attribute, a list of RowData objects in the data attribute, and a list of column names in the columns attribute. It also provides a `to_pandas` method to convert the dataframe into a Pandas DataFrame.\n",
        "\n",
        "The Database class represents a set of tables in a database. It contains a list of Dataframe objects in the tables attribute."
      ],
      "metadata": {
        "id": "ijXj0ubtA3-W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def dataframe(data: str) -> Database:\n",
        "    completion = openai.ChatCompletion.create(\n",
        "        model=\"gpt-4-0613\", # Notice I have to use gpt-4 here, this task is pretty hard\n",
        "        temperature=0.0,\n",
        "        functions=[Database.openai_schema],\n",
        "        function_call={\"name\": Database.openai_schema[\"name\"]},\n",
        "        messages=[\n",
        "            {\n",
        "                \"role\": \"system\",\n",
        "                \"content\": \"\"\"Map this data into a dataframe a\n",
        "                nd correctly define the correct columns and rows\"\"\",\n",
        "            },\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": f\"{data}\",\n",
        "            },\n",
        "        ],\n",
        "        max_tokens=1000,\n",
        "    )\n",
        "    return Database.from_response(completion)"
      ],
      "metadata": {
        "id": "IVYhmn4CAIRO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluating the extraction\n",
        "\n",
        "Let's evaluate the example by converting a text into dataframes using the dataframe function and print the resulting dataframes."
      ],
      "metadata": {
        "id": "s0Qx6jdBBI02"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dfs = dataframe(\"\"\"My name is John and I am 25 years old. I live in\n",
        "New York and I like to play basketball. His name is\n",
        "Mike and he is 30 years old. He lives in San Francisco\n",
        "and he likes to play baseball. Sarah is 20 years old\n",
        "and she lives in Los Angeles. She likes to play tennis.\n",
        "Her name is Mary and she is 35 years old.\n",
        "She lives in Chicago.\n",
        "\n",
        "On one team 'Tigers' the captain is John and there are 12 players.\n",
        "On the other team 'Lions' the captain is Mike and there are 10 players.\n",
        "\"\"\")"
      ],
      "metadata": {
        "id": "yl0Mw49rBGKY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for df in dfs.tables:\n",
        "  print(df.name)\n",
        "  print(df.to_pandas())\n",
        "  print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bQM5yYHg7XqH",
        "outputId": "b45c0826-5449-45fa-c8ae-d6dbc8bcd2a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "People\n",
            "    Name  Age           City Favorite Sport\n",
            "0   John   25       New York     Basketball\n",
            "1   Mike   30  San Francisco       Baseball\n",
            "2  Sarah   20    Los Angeles         Tennis\n",
            "3   Mary   35        Chicago           None\n",
            "\n",
            "Teams\n",
            "  Team Name Captain  Number of Players\n",
            "0    Tigers    John                 12\n",
            "1     Lions    Mike                 10\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Is this the end of prompt engineering?\n",
        "\n",
        "No.\n",
        "\n",
        "You'll find that when you build your own examples, naming variables, docstrings, and descriptions are incredibly important. However now its a matter of writing good code and documentation, since the naming and documentation is used by both human and ai.\n",
        "\n",
        "## Tips on writting good schemas\n",
        "\n",
        "When a schema isn't parsing correctly consider the following tips:\n",
        "\n",
        "1. Don't use generic attributes names\n",
        "2. Every class should have a docstring\n",
        "3. Include tips and few shot examples in the docstrings when needed\n",
        "3. Adjectives on descriptions matter 'short and concise' query will be different that 'detailed and sepicific, include additional keywords'"
      ],
      "metadata": {
        "id": "C3RAa1P4DIi1"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "G5Xrfk5w7vmX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}